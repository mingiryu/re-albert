{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TextAttack.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "daMpHCFFcchY"
      },
      "source": [
        "!pip install textattack torch transformers sentencepiece torchfile"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WyBMREfDnL8D"
      },
      "source": [
        "# BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLNRbJynnM7j",
        "outputId": "e0bdd7e9-1d6c-4215-dece-3eabf66bb9f5"
      },
      "source": [
        "%time !textattack attack --model bert-base-uncased-rte --recipe textfooler --num-examples 10"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reusing dataset glue (/root/.cache/huggingface/datasets/glue/rte/1.0.0/7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4)\n",
            "\u001b[34;1mtextattack\u001b[0m: Loading \u001b[94mdatasets\u001b[0m dataset \u001b[94mglue\u001b[0m, subset \u001b[94mrte\u001b[0m, split \u001b[94mvalidation\u001b[0m.\n",
            "\u001b[34;1mtextattack\u001b[0m: Loading pre-trained model from HuggingFace model repository: \u001b[94mtextattack/bert-base-uncased-RTE\u001b[0m\n",
            "Using /tmp/tfhub_modules to cache modules.\n",
            "\u001b[34;1mtextattack\u001b[0m: Unknown if model of class <class 'transformers.models.bert.modeling_bert.BertForSequenceClassification'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.\n",
            "Attack(\n",
            "  (search_method): GreedyWordSwapWIR(\n",
            "    (wir_method):  delete\n",
            "  )\n",
            "  (goal_function):  UntargetedClassification\n",
            "  (transformation):  WordSwapEmbedding(\n",
            "    (max_candidates):  50\n",
            "    (embedding):  WordEmbedding\n",
            "  )\n",
            "  (constraints): \n",
            "    (0): WordEmbeddingDistance(\n",
            "        (embedding):  WordEmbedding\n",
            "        (min_cos_sim):  0.5\n",
            "        (cased):  False\n",
            "        (include_unknown_words):  True\n",
            "        (compare_against_original):  True\n",
            "      )\n",
            "    (1): PartOfSpeech(\n",
            "        (tagger_type):  nltk\n",
            "        (tagset):  universal\n",
            "        (allow_verb_noun_swap):  True\n",
            "        (compare_against_original):  True\n",
            "      )\n",
            "    (2): UniversalSentenceEncoder(\n",
            "        (metric):  angular\n",
            "        (threshold):  0.840845057\n",
            "        (window_size):  15\n",
            "        (skip_text_shorter_than_window):  True\n",
            "        (compare_against_original):  False\n",
            "      )\n",
            "    (3): RepeatModification\n",
            "    (4): StopwordModification\n",
            "    (5): InputColumnModification(\n",
            "        (matching_column_labels):  ['premise', 'hypothesis']\n",
            "        (columns_to_ignore):  {'premise'}\n",
            "      )\n",
            "  (is_black_box):  True\n",
            ") \n",
            "\n",
            "\u001b[34;1mtextattack\u001b[0m: Load time: 45.47101926803589s\n",
            "  0% 0/10 [00:00<?, ?it/s]--------------------------------------------- Result 1 ---------------------------------------------\n",
            "\u001b[92mNot_entailment (96%)\u001b[0m --> \u001b[37m[SKIPPED]\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: The Tuesday drawing of the Italian Superenalotto game has awarded the biggest prize ever won in a betting game in Italy. The single winner of the first category prize (6 numbers guessed) will receive an amount, including the jackpot from previous un-won draws, of €72.090.405,19 (US$93 million.) The prize money will be received in full without further taxation, since taxes in prizes of that type are taken at a fixed rate by the Italian State from the money paid for the bet.\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: Superenalotto awarded a prize of more than 72 million euros.\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Total] 0 / 0 / 1:  10% 1/10 [00:00<00:00, 31.38it/s]--------------------------------------------- Result 2 ---------------------------------------------\n",
            "\u001b[92mEntailment (95%)\u001b[0m --> \u001b[92mNot_entailment (88%)\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: Rotorua has banned criminals with five or more dishonesty convictions from entering the Central Business District (CBD). The criminals will be issued with trespass notices banning them from the main streets of Rotorua. Eleven out of twelve councillors, including the Rotorua mayor, supported the by-law along with support from the police. Kevin Winters, Mayor of Rotorua, said \"The ban also had the support of local businesses, who wanted an end to the thefts, assaults, shoplifting and other street crime on Rotorua streets. Crime was an issue in the area. Five strikes and you're out.\"\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: The Central Business District (\u001b[92mCBD\u001b[0m) is part of Rotorua.\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: Rotorua has banned criminals with five or more dishonesty convictions from entering the Central Business District (CBD). The criminals will be issued with trespass notices banning them from the main streets of Rotorua. Eleven out of twelve councillors, including the Rotorua mayor, supported the by-law along with support from the police. Kevin Winters, Mayor of Rotorua, said \"The ban also had the support of local businesses, who wanted an end to the thefts, assaults, shoplifting and other street crime on Rotorua streets. Crime was an issue in the area. Five strikes and you're out.\"\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: The Central Business District (\u001b[92mASN\u001b[0m) is part of Rotorua.\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Total] 1 / 0 / 2:  20% 2/10 [00:03<00:15,  1.94s/it]--------------------------------------------- Result 3 ---------------------------------------------\n",
            "\u001b[92mNot_entailment (98%)\u001b[0m --> \u001b[92mEntailment (51%)\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: Mrs. Bush's approval \u001b[92mratings\u001b[0m have remained very high, above 80%, even as her husband's have recently \u001b[92mdropped\u001b[0m below 50%.\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: 80% \u001b[92mapprove\u001b[0m of Mr. Bush.\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: Mrs. Bush's approval \u001b[92mranking\u001b[0m have remained very high, above 80%, even as her husband's have recently \u001b[92mdrop\u001b[0m below 50%.\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: 80% \u001b[92mendorsement\u001b[0m of Mr. Bush.\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Total] 2 / 0 / 3:  30% 3/10 [00:06<00:15,  2.20s/it]--------------------------------------------- Result 4 ---------------------------------------------\n",
            "\u001b[92mNot_entailment (97%)\u001b[0m --> \u001b[37m[SKIPPED]\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: Nokia, Texas Instruments and other leading makers of mobile phones have formally complained to Brussels that Qualcomm, the US mobile chipmaker, has unfairly used its patents on 3G technologies.\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: Texas Instruments produces mobile phones.\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Total] 2 / 0 / 4:  40% 4/10 [00:06<00:09,  1.65s/it]--------------------------------------------- Result 5 ---------------------------------------------\n",
            "\u001b[92mEntailment (91%)\u001b[0m --> \u001b[92mNot_entailment (97%)\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: A plane crashed in North Carolina last year and most of the Blink-182 group was in there. The only survivors of the crash were DJ AM and musical partner Travis Barker. Less lucky, \"Lil\" Chris Baker, Barker's close friend and assistant, the Blink-182 drummer's bodyguard, Charles \"Che\" Still, the pilot and co-pilot died. Both AM and Barker suffered many injures, bad burns and they needed to stay in hospital for several weeks. Now AM asks $20 million in compensation for injuries he suffered. He lawsuits against plane maker Learjet and wants to gain $10 million for medical damages, lost earnings and profit and the same amount for mental and physical suffering.\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: Travis Barker belongs to a \u001b[92mband\u001b[0m.\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: A plane crashed in North Carolina last year and most of the Blink-182 group was in there. The only survivors of the crash were DJ AM and musical partner Travis Barker. Less lucky, \"Lil\" Chris Baker, Barker's close friend and assistant, the Blink-182 drummer's bodyguard, Charles \"Che\" Still, the pilot and co-pilot died. Both AM and Barker suffered many injures, bad burns and they needed to stay in hospital for several weeks. Now AM asks $20 million in compensation for injuries he suffered. He lawsuits against plane maker Learjet and wants to gain $10 million for medical damages, lost earnings and profit and the same amount for mental and physical suffering.\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: Travis Barker belongs to a \u001b[92mbanda\u001b[0m.\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Total] 3 / 0 / 5:  50% 5/10 [00:08<00:08,  1.71s/it]--------------------------------------------- Result 6 ---------------------------------------------\n",
            "\u001b[92mEntailment (72%)\u001b[0m --> \u001b[92mNot_entailment (73%)\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: A farmer who was in contact with cows suffering from BSE -- the so-called mad cow disease -- has died from what is regarded as the human form of the disease.\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: Bovine spongiform encephalopathy is another \u001b[92mname\u001b[0m for the \"mad cow disease\".\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: A farmer who was in contact with cows suffering from BSE -- the so-called mad cow disease -- has died from what is regarded as the human form of the disease.\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: Bovine spongiform encephalopathy is another \u001b[92mnoun\u001b[0m for the \"mad cow disease\".\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Total] 4 / 0 / 6:  60% 6/10 [00:09<00:06,  1.58s/it]--------------------------------------------- Result 7 ---------------------------------------------\n",
            "\u001b[92mEntailment (89%)\u001b[0m --> \u001b[92mNot_entailment (66%)\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: Evans \u001b[92mPaul\u001b[0m, the pro-Aristide \u001b[92mmayor\u001b[0m of Port-au-Prince, said he had been told that the money will go to American lobbyists, politicians and journalists to campaign against the return of Aristide, Haiti's first democratically elected president\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: Evans Paul is the mayor of Port-au-Prince.\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: Evans \u001b[92mPaulus\u001b[0m, the pro-Aristide \u001b[92mgovernor\u001b[0m of Port-au-Prince, said he had been told that the money will go to American lobbyists, politicians and journalists to campaign against the return of Aristide, Haiti's first democratically elected president\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: Evans Paul is the mayor of Port-au-Prince.\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Total] 5 / 0 / 7:  70% 7/10 [00:10<00:04,  1.47s/it]--------------------------------------------- Result 8 ---------------------------------------------\n",
            "\u001b[92mNot_entailment (97%)\u001b[0m --> \u001b[92mEntailment (71%)\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: Two British soldiers have been \u001b[92marrested\u001b[0m in the southern Iraq city of Basra, sparking clashes outside a police station where they are being \u001b[92mheld\u001b[0m.\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: Two British \u001b[92mtanks\u001b[0m, sent to the police station where the \u001b[92msoldiers\u001b[0m are being held, were set alight in clashes.\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: Two British soldiers have been \u001b[92mcapturing\u001b[0m in the southern Iraq city of Basra, sparking clashes outside a police station where they are being \u001b[92mretains\u001b[0m.\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: Two British \u001b[92mtank\u001b[0m, sent to the police station where the \u001b[92mmilitaries\u001b[0m are being held, were set alight in clashes.\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Total] 6 / 0 / 8:  80% 8/10 [00:12<00:03,  1.58s/it]--------------------------------------------- Result 9 ---------------------------------------------\n",
            "\u001b[92mEntailment (95%)\u001b[0m --> \u001b[92mNot_entailment (71%)\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: singer and actress Britney Spears, 24, has filled papers in Los Angeles County Superior Court to \u001b[92mdivorce\u001b[0m her husband Kevin Federline, 28. A spokeswoman for the court, Kathy Roberts stated that the papers cited irreconcilable differences\" as the reason for the divorce and have, according to the courts, been legally separated as of Monday, November 6, the same day that Spears appeared on Late Night with David Letterman.\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: \u001b[92mSpears\u001b[0m is to divorce from Kevin Federline.\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: singer and actress Britney Spears, 24, has filled papers in Los Angeles County Superior Court to \u001b[92mdivorcing\u001b[0m her husband Kevin Federline, 28. A spokeswoman for the court, Kathy Roberts stated that the papers cited irreconcilable differences\" as the reason for the divorce and have, according to the courts, been legally separated as of Monday, November 6, the same day that Spears appeared on Late Night with David Letterman.\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: \u001b[92mHarpoons\u001b[0m is to divorce from Kevin Federline.\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Total] 7 / 0 / 9:  90% 9/10 [00:14<00:01,  1.60s/it]--------------------------------------------- Result 10 ---------------------------------------------\n",
            "\u001b[92mEntailment (90%)\u001b[0m --> \u001b[92mNot_entailment (94%)\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: U.S. forces have been engaged in intense fighting after insurgents launched simultaneous attacks in several \u001b[92mIraqi\u001b[0m cities, including Fallujah and Baqubah.\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: Fallujah and Baqubah are Iraqi cities.\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: U.S. forces have been engaged in intense fighting after insurgents launched simultaneous attacks in several \u001b[92mBagdad\u001b[0m cities, including Fallujah and Baqubah.\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: Fallujah and Baqubah are Iraqi cities.\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Total] 8 / 0 / 10: 100% 10/10 [00:15<00:00,  1.52s/it]\n",
            "\n",
            "+-------------------------------+--------+\n",
            "| Attack Results                |        |\n",
            "+-------------------------------+--------+\n",
            "| Number of successful attacks: | 8      |\n",
            "| Number of failed attacks:     | 0      |\n",
            "| Number of skipped attacks:    | 2      |\n",
            "| Original accuracy:            | 80.0%  |\n",
            "| Accuracy under attack:        | 0.0%   |\n",
            "| Attack success rate:          | 100.0% |\n",
            "| Average perturbed word %:     | 4.64%  |\n",
            "| Average num. words per input: | 60.2   |\n",
            "| Avg num queries:              | 103.25 |\n",
            "+-------------------------------+--------+\n",
            "\u001b[34;1mtextattack\u001b[0m: Attack time: 15.159240007400513s\n",
            "CPU times: user 129 ms, sys: 13.9 ms, total: 142 ms\n",
            "Wall time: 1min 11s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRKEJSU4nQ_5",
        "outputId": "89699fbc-bbe4-4bbe-be94-b85b4b4ee090"
      },
      "source": [
        "%time !textattack attack --model bert-base-uncased-rte --recipe iga --num-examples 10"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reusing dataset glue (/root/.cache/huggingface/datasets/glue/rte/1.0.0/7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4)\n",
            "\u001b[34;1mtextattack\u001b[0m: Loading \u001b[94mdatasets\u001b[0m dataset \u001b[94mglue\u001b[0m, subset \u001b[94mrte\u001b[0m, split \u001b[94mvalidation\u001b[0m.\n",
            "\u001b[34;1mtextattack\u001b[0m: Loading pre-trained model from HuggingFace model repository: \u001b[94mtextattack/bert-base-uncased-RTE\u001b[0m\n",
            "\u001b[34;1mtextattack\u001b[0m: Unknown if model of class <class 'transformers.models.bert.modeling_bert.BertForSequenceClassification'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.\n",
            "Attack(\n",
            "  (search_method): ImprovedGeneticAlgorithm(\n",
            "    (pop_size):  60\n",
            "    (max_iters):  20\n",
            "    (temp):  0.3\n",
            "    (give_up_if_no_improvement):  False\n",
            "    (post_crossover_check):  False\n",
            "    (max_crossover_retries):  20\n",
            "    (max_replace_times_per_index):  5\n",
            "  )\n",
            "  (goal_function):  UntargetedClassification\n",
            "  (transformation):  WordSwapEmbedding(\n",
            "    (max_candidates):  50\n",
            "    (embedding):  WordEmbedding\n",
            "  )\n",
            "  (constraints): \n",
            "    (0): MaxWordsPerturbed(\n",
            "        (max_percent):  0.2\n",
            "        (compare_against_original):  True\n",
            "      )\n",
            "    (1): WordEmbeddingDistance(\n",
            "        (embedding):  WordEmbedding\n",
            "        (max_mse_dist):  0.5\n",
            "        (cased):  False\n",
            "        (include_unknown_words):  True\n",
            "        (compare_against_original):  False\n",
            "      )\n",
            "    (2): StopwordModification\n",
            "  (is_black_box):  True\n",
            ") \n",
            "\n",
            "\u001b[34;1mtextattack\u001b[0m: Load time: 21.670477390289307s\n",
            "  0% 0/10 [00:00<?, ?it/s]--------------------------------------------- Result 1 ---------------------------------------------\n",
            "\u001b[92mNot_entailment (96%)\u001b[0m --> \u001b[37m[SKIPPED]\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: The Tuesday drawing of the Italian Superenalotto game has awarded the biggest prize ever won in a betting game in Italy. The single winner of the first category prize (6 numbers guessed) will receive an amount, including the jackpot from previous un-won draws, of €72.090.405,19 (US$93 million.) The prize money will be received in full without further taxation, since taxes in prizes of that type are taken at a fixed rate by the Italian State from the money paid for the bet.\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: Superenalotto awarded a prize of more than 72 million euros.\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Total] 0 / 0 / 1:  10% 1/10 [00:00<00:00, 32.80it/s]--------------------------------------------- Result 2 ---------------------------------------------\n",
            "\u001b[92mEntailment (95%)\u001b[0m --> \u001b[92mNot_entailment (96%)\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: Rotorua has banned criminals with five or more dishonesty \u001b[92mconvictions\u001b[0m from entering the Central Business District (CBD). The criminals will be issued with trespass notices banning them from the main streets of Rotorua. Eleven out of twelve councillors, including the Rotorua mayor, supported the by-law along with support from the police. Kevin Winters, Mayor of Rotorua, said \"The ban also had the support of local businesses, who wanted an end to the thefts, assaults, shoplifting and other street crime on Rotorua streets. Crime was an issue in the area. Five strikes and you're out.\"\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: The Central Business \u001b[92mDistrict\u001b[0m (CBD) is part of Rotorua.\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: Rotorua has banned criminals with five or more dishonesty \u001b[92mpriors\u001b[0m from entering the Central Business District (CBD). The criminals will be issued with trespass notices banning them from the main streets of Rotorua. Eleven out of twelve councillors, including the Rotorua mayor, supported the by-law along with support from the police. Kevin Winters, Mayor of Rotorua, said \"The ban also had the support of local businesses, who wanted an end to the thefts, assaults, shoplifting and other street crime on Rotorua streets. Crime was an issue in the area. Five strikes and you're out.\"\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: The Central Business \u001b[92mArrondissement\u001b[0m (CBD) is part of Rotorua.\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Total] 1 / 0 / 2:  20% 2/10 [00:31<02:07, 15.94s/it]--------------------------------------------- Result 3 ---------------------------------------------\n",
            "\u001b[92mNot_entailment (98%)\u001b[0m --> \u001b[92mEntailment (52%)\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: Mrs. Bush's \u001b[92mapproval\u001b[0m ratings have \u001b[92mremained\u001b[0m very \u001b[92mhigh\u001b[0m, above 80%, even as her husband's have recently \u001b[92mdropped\u001b[0m below 50%.\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: 80% \u001b[92mapprove\u001b[0m of Mr. Bush.\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: Mrs. Bush's \u001b[92mendorsement\u001b[0m ratings have \u001b[92mpersevere\u001b[0m very \u001b[92mhaut\u001b[0m, above 80%, even as her husband's have recently \u001b[92mplummeted\u001b[0m below 50%.\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: 80% \u001b[92mendorsement\u001b[0m of Mr. Bush.\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Total] 2 / 0 / 3:  30% 3/10 [01:55<04:29, 38.45s/it]--------------------------------------------- Result 4 ---------------------------------------------\n",
            "\u001b[92mNot_entailment (97%)\u001b[0m --> \u001b[37m[SKIPPED]\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: Nokia, Texas Instruments and other leading makers of mobile phones have formally complained to Brussels that Qualcomm, the US mobile chipmaker, has unfairly used its patents on 3G technologies.\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: Texas Instruments produces mobile phones.\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Total] 2 / 0 / 4:  40% 4/10 [01:55<02:53, 28.84s/it]--------------------------------------------- Result 5 ---------------------------------------------\n",
            "\u001b[92mEntailment (91%)\u001b[0m --> \u001b[92mNot_entailment (97%)\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: A plane crashed in North Carolina last year and most of the Blink-182 group was in there. The only survivors of the crash were DJ AM and musical partner Travis Barker. Less lucky, \"Lil\" Chris Baker, Barker's close friend and assistant, the Blink-182 drummer's bodyguard, Charles \"Che\" Still, the pilot and co-pilot died. Both AM and Barker suffered many injures, bad burns and they needed to stay in hospital for several weeks. Now AM asks $20 million in compensation for injuries he suffered. He lawsuits against plane maker Learjet and wants to gain $10 million for medical damages, lost earnings and profit and the same amount for mental and physical suffering.\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: Travis Barker belongs to a \u001b[92mband\u001b[0m.\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: A plane crashed in North Carolina last year and most of the Blink-182 group was in there. The only survivors of the crash were DJ AM and musical partner Travis Barker. Less lucky, \"Lil\" Chris Baker, Barker's close friend and assistant, the Blink-182 drummer's bodyguard, Charles \"Che\" Still, the pilot and co-pilot died. Both AM and Barker suffered many injures, bad burns and they needed to stay in hospital for several weeks. Now AM asks $20 million in compensation for injuries he suffered. He lawsuits against plane maker Learjet and wants to gain $10 million for medical damages, lost earnings and profit and the same amount for mental and physical suffering.\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: Travis Barker belongs to a \u001b[92mbanda\u001b[0m.\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Total] 3 / 0 / 5:  50% 5/10 [03:31<03:31, 42.35s/it]--------------------------------------------- Result 6 ---------------------------------------------\n",
            "\u001b[92mEntailment (72%)\u001b[0m --> \u001b[92mNot_entailment (94%)\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: A farmer who was in contact with cows suffering from BSE -- the so-called mad cow disease -- has died from what is regarded as the human form of the disease.\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: Bovine spongiform encephalopathy is another name for the \"\u001b[92mmad\u001b[0m cow disease\".\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: A farmer who was in contact with cows suffering from BSE -- the so-called mad cow disease -- has died from what is regarded as the human form of the disease.\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: Bovine spongiform encephalopathy is another name for the \"\u001b[92mlivid\u001b[0m cow disease\".\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Total] 4 / 0 / 6:  60% 6/10 [03:35<02:23, 35.94s/it]--------------------------------------------- Result 7 ---------------------------------------------\n",
            "\u001b[92mEntailment (89%)\u001b[0m --> \u001b[92mNot_entailment (97%)\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: Evans Paul, the pro-Aristide mayor of Port-au-Prince, said he had been told that the money will go to American lobbyists, politicians and journalists to campaign against the return of Aristide, Haiti's first democratically elected president\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: Evans Paul is the \u001b[92mmayor\u001b[0m of Port-au-Prince.\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: Evans Paul, the pro-Aristide mayor of Port-au-Prince, said he had been told that the money will go to American lobbyists, politicians and journalists to campaign against the return of Aristide, Haiti's first democratically elected president\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: Evans Paul is the \u001b[92mmaire\u001b[0m of Port-au-Prince.\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Total] 5 / 0 / 7:  70% 7/10 [03:38<01:33, 31.20s/it]--------------------------------------------- Result 8 ---------------------------------------------\n",
            "\u001b[92mNot_entailment (97%)\u001b[0m --> \u001b[92mEntailment (71%)\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: Two British \u001b[92msoldiers\u001b[0m have been \u001b[92marrested\u001b[0m in the southern Iraq city of Basra, sparking clashes \u001b[92moutside\u001b[0m a police station where they are being held.\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: Two British tanks, sent to the \u001b[92mpolice\u001b[0m station where the soldiers are being held, were set alight in clashes.\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: Two British \u001b[92msolider\u001b[0m have been \u001b[92mcaptured\u001b[0m in the southern Iraq city of Basra, sparking clashes \u001b[92moutboard\u001b[0m a police station where they are being held.\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: Two British tanks, sent to the \u001b[92mpolicing\u001b[0m station where the soldiers are being held, were set alight in clashes.\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Total] 6 / 0 / 8:  80% 8/10 [03:56<00:59, 29.53s/it]--------------------------------------------- Result 9 ---------------------------------------------\n",
            "\u001b[92mEntailment (95%)\u001b[0m --> \u001b[92mNot_entailment (69%)\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: singer and actress \u001b[92mBritney\u001b[0m \u001b[92mSpears\u001b[0m, 24, has filled papers in Los Angeles County Superior Court to divorce her husband Kevin Federline, 28. A spokeswoman for the court, Kathy Roberts stated that the papers cited irreconcilable differences\" as the reason for the divorce and have, according to the courts, been legally separated as of Monday, November 6, the same day that Spears appeared on Late Night with David Letterman.\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: \u001b[92mSpears\u001b[0m is to divorce from Kevin Federline.\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: singer and actress \u001b[92mAguilera\u001b[0m \u001b[92mLances\u001b[0m, 24, has filled papers in Los Angeles County Superior Court to divorce her husband Kevin Federline, 28. A spokeswoman for the court, Kathy Roberts stated that the papers cited irreconcilable differences\" as the reason for the divorce and have, according to the courts, been legally separated as of Monday, November 6, the same day that Spears appeared on Late Night with David Letterman.\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: \u001b[92mHarpoons\u001b[0m is to divorce from Kevin Federline.\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Total] 7 / 0 / 9:  90% 9/10 [04:22<00:29, 29.16s/it]--------------------------------------------- Result 10 ---------------------------------------------\n",
            "\u001b[92mEntailment (90%)\u001b[0m --> \u001b[92mNot_entailment (98%)\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: U.S. forces have been engaged in intense fighting after insurgents launched simultaneous attacks in several Iraqi cities, including Fallujah and Baqubah.\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: Fallujah and Baqubah are Iraqi \u001b[92mcities\u001b[0m.\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: U.S. forces have been engaged in intense fighting after insurgents launched simultaneous attacks in several Iraqi cities, including Fallujah and Baqubah.\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: Fallujah and Baqubah are Iraqi \u001b[92mtownships\u001b[0m.\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Total] 8 / 0 / 10: 100% 10/10 [04:26<00:00, 26.67s/it]\n",
            "\n",
            "+-------------------------------+---------+\n",
            "| Attack Results                |         |\n",
            "+-------------------------------+---------+\n",
            "| Number of successful attacks: | 8       |\n",
            "| Number of failed attacks:     | 0       |\n",
            "| Number of skipped attacks:    | 2       |\n",
            "| Original accuracy:            | 80.0%   |\n",
            "| Accuracy under attack:        | 0.0%    |\n",
            "| Attack success rate:          | 100.0%  |\n",
            "| Average perturbed word %:     | 5.67%   |\n",
            "| Average num. words per input: | 60.2    |\n",
            "| Avg num queries:              | 2466.88 |\n",
            "+-------------------------------+---------+\n",
            "\u001b[34;1mtextattack\u001b[0m: Attack time: 266.6768047809601s\n",
            "CPU times: user 323 ms, sys: 59 ms, total: 382 ms\n",
            "Wall time: 5min 4s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJPZ1RqpnVDQ",
        "outputId": "208390ab-0aa0-46a9-9432-95c5d58dc718"
      },
      "source": [
        "%time !textattack attack --model bert-base-uncased-rte --recipe faster-alzantot --num-examples 10"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reusing dataset glue (/root/.cache/huggingface/datasets/glue/rte/1.0.0/7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4)\n",
            "\u001b[34;1mtextattack\u001b[0m: Loading \u001b[94mdatasets\u001b[0m dataset \u001b[94mglue\u001b[0m, subset \u001b[94mrte\u001b[0m, split \u001b[94mvalidation\u001b[0m.\n",
            "\u001b[34;1mtextattack\u001b[0m: Loading pre-trained model from HuggingFace model repository: \u001b[94mtextattack/bert-base-uncased-RTE\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:61: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.01 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "\u001b[34;1mtextattack\u001b[0m: Unknown if model of class <class 'transformers.models.bert.modeling_bert.BertForSequenceClassification'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.\n",
            "Attack(\n",
            "  (search_method): AlzantotGeneticAlgorithm(\n",
            "    (pop_size):  60\n",
            "    (max_iters):  20\n",
            "    (temp):  0.3\n",
            "    (give_up_if_no_improvement):  False\n",
            "    (post_crossover_check):  False\n",
            "    (max_crossover_retries):  20\n",
            "  )\n",
            "  (goal_function):  UntargetedClassification\n",
            "  (transformation):  WordSwapEmbedding(\n",
            "    (max_candidates):  8\n",
            "    (embedding):  WordEmbedding\n",
            "  )\n",
            "  (constraints): \n",
            "    (0): MaxWordsPerturbed(\n",
            "        (max_percent):  0.2\n",
            "        (compare_against_original):  True\n",
            "      )\n",
            "    (1): WordEmbeddingDistance(\n",
            "        (embedding):  WordEmbedding\n",
            "        (max_mse_dist):  0.5\n",
            "        (cased):  False\n",
            "        (include_unknown_words):  True\n",
            "        (compare_against_original):  True\n",
            "      )\n",
            "    (2): LearningToWriteLanguageModel(\n",
            "        (max_log_prob_diff):  5.0\n",
            "        (compare_against_original):  True\n",
            "      )\n",
            "    (3): RepeatModification\n",
            "    (4): StopwordModification\n",
            "  (is_black_box):  True\n",
            ") \n",
            "\n",
            "\u001b[34;1mtextattack\u001b[0m: Load time: 58.995662212371826s\n",
            "  0% 0/10 [00:00<?, ?it/s]--------------------------------------------- Result 1 ---------------------------------------------\n",
            "\u001b[92mNot_entailment (96%)\u001b[0m --> \u001b[37m[SKIPPED]\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: The Tuesday drawing of the Italian Superenalotto game has awarded the biggest prize ever won in a betting game in Italy. The single winner of the first category prize (6 numbers guessed) will receive an amount, including the jackpot from previous un-won draws, of €72.090.405,19 (US$93 million.) The prize money will be received in full without further taxation, since taxes in prizes of that type are taken at a fixed rate by the Italian State from the money paid for the bet.\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: Superenalotto awarded a prize of more than 72 million euros.\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Total] 0 / 0 / 1:  10% 1/10 [00:00<00:00, 14.69it/s]--------------------------------------------- Result 2 ---------------------------------------------\n",
            "\u001b[92mEntailment (95%)\u001b[0m --> \u001b[92mNot_entailment (75%)\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: Rotorua has banned criminals with five or more dishonesty convictions from entering the Central Business District (CBD). The criminals will be issued with trespass notices banning them from the main streets of Rotorua. Eleven out of twelve councillors, including the Rotorua mayor, supported the by-law along with support from the police. Kevin Winters, Mayor of Rotorua, said \"The ban also had the support of local businesses, who wanted an end to the thefts, assaults, shoplifting and other street crime on Rotorua streets. Crime was an issue in the area. Five strikes and you're out.\"\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: The Central \u001b[92mBusiness\u001b[0m District (CBD) is part of Rotorua.\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: Rotorua has banned criminals with five or more dishonesty convictions from entering the Central Business District (CBD). The criminals will be issued with trespass notices banning them from the main streets of Rotorua. Eleven out of twelve councillors, including the Rotorua mayor, supported the by-law along with support from the police. Kevin Winters, Mayor of Rotorua, said \"The ban also had the support of local businesses, who wanted an end to the thefts, assaults, shoplifting and other street crime on Rotorua streets. Crime was an issue in the area. Five strikes and you're out.\"\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: The Central \u001b[92mEntrepreneurial\u001b[0m District (CBD) is part of Rotorua.\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Total] 1 / 0 / 2:  20% 2/10 [00:22<01:28, 11.11s/it]--------------------------------------------- Result 3 ---------------------------------------------\n",
            "\u001b[92mNot_entailment (98%)\u001b[0m --> \u001b[92mEntailment (51%)\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: \u001b[92mMrs\u001b[0m. Bush's approval ratings have \u001b[92mremained\u001b[0m very high, above 80%, \u001b[92meven\u001b[0m as her husband's have recently \u001b[92mdropped\u001b[0m below 50%.\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: 80% \u001b[92mapprove\u001b[0m of Mr. Bush.\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: \u001b[92mNadja\u001b[0m. Bush's approval ratings have \u001b[92mmaintained\u001b[0m very high, above 80%, \u001b[92mso\u001b[0m as her husband's have recently \u001b[92mdip\u001b[0m below 50%.\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: 80% \u001b[92mendorsement\u001b[0m of Mr. Bush.\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Total] 2 / 0 / 3:  30% 3/10 [01:04<02:31, 21.66s/it]--------------------------------------------- Result 4 ---------------------------------------------\n",
            "\u001b[92mNot_entailment (97%)\u001b[0m --> \u001b[37m[SKIPPED]\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: Nokia, Texas Instruments and other leading makers of mobile phones have formally complained to Brussels that Qualcomm, the US mobile chipmaker, has unfairly used its patents on 3G technologies.\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: Texas Instruments produces mobile phones.\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Total] 2 / 0 / 4:  40% 4/10 [01:04<01:37, 16.25s/it]--------------------------------------------- Result 5 ---------------------------------------------\n",
            "\u001b[92mEntailment (91%)\u001b[0m --> \u001b[92mNot_entailment (74%)\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: A plane crashed in North Carolina last year and most of the Blink-182 group was in there. The only survivors of the crash were DJ AM and musical partner Travis Barker. Less lucky, \"Lil\" Chris Baker, Barker's close friend and assistant, the Blink-182 drummer's bodyguard, Charles \"Che\" Still, the pilot and co-pilot died. Both AM and Barker suffered many injures, bad burns and they needed to stay in hospital for several weeks. Now AM asks $20 million in compensation for injuries he suffered. He lawsuits against plane maker Learjet and \u001b[92mwants\u001b[0m to gain $10 million for medical damages, lost earnings and profit and the same amount for mental and physical suffering.\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: Travis \u001b[92mBarker\u001b[0m belongs to a band.\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: A plane crashed in North Carolina last year and most of the Blink-182 group was in there. The only survivors of the crash were DJ AM and musical partner Travis Barker. Less lucky, \"Lil\" Chris Baker, Barker's close friend and assistant, the Blink-182 drummer's bodyguard, Charles \"Che\" Still, the pilot and co-pilot died. Both AM and Barker suffered many injures, bad burns and they needed to stay in hospital for several weeks. Now AM asks $20 million in compensation for injuries he suffered. He lawsuits against plane maker Learjet and \u001b[92mwanting\u001b[0m to gain $10 million for medical damages, lost earnings and profit and the same amount for mental and physical suffering.\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: Travis \u001b[92mParker\u001b[0m belongs to a band.\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Total] 3 / 0 / 5:  50% 5/10 [01:32<01:32, 18.47s/it]--------------------------------------------- Result 6 ---------------------------------------------\n",
            "\u001b[92mEntailment (72%)\u001b[0m --> \u001b[92mNot_entailment (81%)\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: A \u001b[92mfarmer\u001b[0m who was in contact with \u001b[92mcows\u001b[0m suffering from BSE -- the so-called mad cow disease -- has died from what is regarded as the human form of the disease.\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: \u001b[92mBovine\u001b[0m spongiform encephalopathy is another name for the \"mad cow disease\".\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: A \u001b[92mfarm\u001b[0m who was in contact with \u001b[92mveal\u001b[0m suffering from BSE -- the so-called mad cow disease -- has died from what is regarded as the human form of the disease.\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: \u001b[92mBeef\u001b[0m spongiform encephalopathy is another name for the \"mad cow disease\".\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Total] 4 / 0 / 6:  60% 6/10 [01:45<01:10, 17.62s/it]--------------------------------------------- Result 7 ---------------------------------------------\n",
            "\u001b[92mEntailment (89%)\u001b[0m --> \u001b[92mNot_entailment (92%)\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: Evans Paul, the pro-Aristide mayor of Port-au-Prince, said he had been told that the money will go to American lobbyists, politicians and journalists to campaign against the return of Aristide, Haiti's first democratically elected president\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: Evans \u001b[92mPaul\u001b[0m is the mayor of Port-au-Prince.\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: Evans Paul, the pro-Aristide mayor of Port-au-Prince, said he had been told that the money will go to American lobbyists, politicians and journalists to campaign against the return of Aristide, Haiti's first democratically elected president\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: Evans \u001b[92mPablo\u001b[0m is the mayor of Port-au-Prince.\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Total] 5 / 0 / 7:  70% 7/10 [01:48<00:46, 15.50s/it]--------------------------------------------- Result 8 ---------------------------------------------\n",
            "\u001b[92mNot_entailment (97%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: Two British soldiers have been arrested in the southern Iraq city of Basra, sparking clashes outside a police station where they are being held.\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: Two British tanks, sent to the police station where the soldiers are being held, were set alight in clashes.\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Total] 5 / 1 / 8:  80% 8/10 [14:32<03:38, 109.09s/it]--------------------------------------------- Result 9 ---------------------------------------------\n",
            "\u001b[92mEntailment (95%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: singer and actress Britney Spears, 24, has filled papers in Los Angeles County Superior Court to divorce her husband Kevin Federline, 28. A spokeswoman for the court, Kathy Roberts stated that the papers cited irreconcilable differences\" as the reason for the divorce and have, according to the courts, been legally separated as of Monday, November 6, the same day that Spears appeared on Late Night with David Letterman.\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: Spears is to divorce from Kevin Federline.\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Total] 5 / 2 / 9:  90% 9/10 [20:08<02:14, 134.26s/it]--------------------------------------------- Result 10 ---------------------------------------------\n",
            "\u001b[92mEntailment (90%)\u001b[0m --> \u001b[92mNot_entailment (95%)\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: U.S. forces have been engaged in intense fighting after insurgents launched simultaneous attacks in several Iraqi cities, including Fallujah and Baqubah.\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: Fallujah and Baqubah are Iraqi \u001b[92mcities\u001b[0m.\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: U.S. forces have been engaged in intense fighting after insurgents launched simultaneous attacks in several Iraqi cities, including Fallujah and Baqubah.\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: Fallujah and Baqubah are Iraqi \u001b[92murban\u001b[0m.\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Total] 6 / 2 / 10: 100% 10/10 [20:11<00:00, 121.13s/it]\n",
            "\n",
            "+-------------------------------+---------+\n",
            "| Attack Results                |         |\n",
            "+-------------------------------+---------+\n",
            "| Number of successful attacks: | 6       |\n",
            "| Number of failed attacks:     | 2       |\n",
            "| Number of skipped attacks:    | 2       |\n",
            "| Original accuracy:            | 80.0%   |\n",
            "| Accuracy under attack:        | 20.0%   |\n",
            "| Attack success rate:          | 75.0%   |\n",
            "| Average perturbed word %:     | 6.16%   |\n",
            "| Average num. words per input: | 60.2    |\n",
            "| Avg num queries:              | 1905.62 |\n",
            "+-------------------------------+---------+\n",
            "\u001b[34;1mtextattack\u001b[0m: Attack time: 1211.3253202438354s\n",
            "CPU times: user 2.36 s, sys: 439 ms, total: 2.8 s\n",
            "Wall time: 21min 22s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwfvIvNvfWWW"
      },
      "source": [
        "# ALBERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VJQsdY9cpTP",
        "outputId": "4beb62f4-d349-4fa0-d65d-bc97ed6367c8"
      },
      "source": [
        "%time !textattack attack --model albert-base-v2-rte --recipe textfooler --num-examples 10"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reusing dataset glue (/root/.cache/huggingface/datasets/glue/rte/1.0.0/7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4)\n",
            "\u001b[34;1mtextattack\u001b[0m: Loading \u001b[94mdatasets\u001b[0m dataset \u001b[94mglue\u001b[0m, subset \u001b[94mrte\u001b[0m, split \u001b[94mvalidation\u001b[0m.\n",
            "\u001b[34;1mtextattack\u001b[0m: Loading pre-trained model from HuggingFace model repository: \u001b[94mtextattack/albert-base-v2-RTE\u001b[0m\n",
            "Using /tmp/tfhub_modules to cache modules.\n",
            "Downloading TF-Hub Module 'https://tfhub.dev/google/universal-sentence-encoder/4'.\n",
            "Downloaded https://tfhub.dev/google/universal-sentence-encoder/4, Total size: 987.47MB\n",
            "Downloaded TF-Hub Module 'https://tfhub.dev/google/universal-sentence-encoder/4'.\n",
            "\u001b[34;1mtextattack\u001b[0m: Unknown if model of class <class 'transformers.models.albert.modeling_albert.AlbertForSequenceClassification'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.\n",
            "Attack(\n",
            "  (search_method): GreedyWordSwapWIR(\n",
            "    (wir_method):  delete\n",
            "  )\n",
            "  (goal_function):  UntargetedClassification\n",
            "  (transformation):  WordSwapEmbedding(\n",
            "    (max_candidates):  50\n",
            "    (embedding):  WordEmbedding\n",
            "  )\n",
            "  (constraints): \n",
            "    (0): WordEmbeddingDistance(\n",
            "        (embedding):  WordEmbedding\n",
            "        (min_cos_sim):  0.5\n",
            "        (cased):  False\n",
            "        (include_unknown_words):  True\n",
            "        (compare_against_original):  True\n",
            "      )\n",
            "    (1): PartOfSpeech(\n",
            "        (tagger_type):  nltk\n",
            "        (tagset):  universal\n",
            "        (allow_verb_noun_swap):  True\n",
            "        (compare_against_original):  True\n",
            "      )\n",
            "    (2): UniversalSentenceEncoder(\n",
            "        (metric):  angular\n",
            "        (threshold):  0.840845057\n",
            "        (window_size):  15\n",
            "        (skip_text_shorter_than_window):  True\n",
            "        (compare_against_original):  False\n",
            "      )\n",
            "    (3): RepeatModification\n",
            "    (4): StopwordModification\n",
            "    (5): InputColumnModification(\n",
            "        (matching_column_labels):  ['premise', 'hypothesis']\n",
            "        (columns_to_ignore):  {'premise'}\n",
            "      )\n",
            "  (is_black_box):  True\n",
            ") \n",
            "\n",
            "\u001b[34;1mtextattack\u001b[0m: Load time: 22.59069323539734s\n",
            "  0% 0/10 [00:00<?, ?it/s]--------------------------------------------- Result 1 ---------------------------------------------\n",
            "\u001b[92mNot_entailment (98%)\u001b[0m --> \u001b[37m[SKIPPED]\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: The Tuesday drawing of the Italian Superenalotto game has awarded the biggest prize ever won in a betting game in Italy. The single winner of the first category prize (6 numbers guessed) will receive an amount, including the jackpot from previous un-won draws, of €72.090.405,19 (US$93 million.) The prize money will be received in full without further taxation, since taxes in prizes of that type are taken at a fixed rate by the Italian State from the money paid for the bet.\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: Superenalotto awarded a prize of more than 72 million euros.\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Total] 0 / 0 / 1:  10% 1/10 [00:00<00:00, 29.30it/s]--------------------------------------------- Result 2 ---------------------------------------------\n",
            "\u001b[92mEntailment (78%)\u001b[0m --> \u001b[92mNot_entailment (77%)\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: Rotorua has banned criminals with five or more dishonesty convictions from entering the Central Business District (\u001b[92mCBD\u001b[0m). The criminals will be issued with trespass notices banning them from the main streets of Rotorua. Eleven out of twelve councillors, including the Rotorua mayor, supported the by-law along with support from the police. Kevin Winters, Mayor of Rotorua, said \"The ban also had the support of local businesses, who wanted an end to the thefts, assaults, shoplifting and other street crime on Rotorua streets. Crime was an issue in the area. Five strikes and you're out.\"\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: The Central Business District (CBD) is part of Rotorua.\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: Rotorua has banned criminals with five or more dishonesty convictions from entering the Central Business District (\u001b[92mASN\u001b[0m). The criminals will be issued with trespass notices banning them from the main streets of Rotorua. Eleven out of twelve councillors, including the Rotorua mayor, supported the by-law along with support from the police. Kevin Winters, Mayor of Rotorua, said \"The ban also had the support of local businesses, who wanted an end to the thefts, assaults, shoplifting and other street crime on Rotorua streets. Crime was an issue in the area. Five strikes and you're out.\"\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: The Central Business District (CBD) is part of Rotorua.\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Total] 1 / 0 / 2:  20% 2/10 [00:04<00:16,  2.11s/it]--------------------------------------------- Result 3 ---------------------------------------------\n",
            "\u001b[92mNot_entailment (95%)\u001b[0m --> \u001b[92mEntailment (60%)\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: Mrs. Bush's approval \u001b[92mratings\u001b[0m have remained very \u001b[92mhigh\u001b[0m, above 80%, even as her husband's \u001b[92mhave\u001b[0m recently dropped below 50%.\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: 80% \u001b[92mapprove\u001b[0m of Mr. Bush.\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: Mrs. Bush's approval \u001b[92mrating\u001b[0m have remained very \u001b[92msupremo\u001b[0m, above 80%, even as her husband's \u001b[92mpossesses\u001b[0m recently dropped below 50%.\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: 80% \u001b[92mapprovals\u001b[0m of Mr. Bush.\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Total] 2 / 0 / 3:  30% 3/10 [00:07<00:17,  2.48s/it]--------------------------------------------- Result 4 ---------------------------------------------\n",
            "\u001b[92mNot_entailment (89%)\u001b[0m --> \u001b[37m[SKIPPED]\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: Nokia, Texas Instruments and other leading makers of mobile phones have formally complained to Brussels that Qualcomm, the US mobile chipmaker, has unfairly used its patents on 3G technologies.\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: Texas Instruments produces mobile phones.\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Total] 2 / 0 / 4:  40% 4/10 [00:07<00:11,  1.87s/it]--------------------------------------------- Result 5 ---------------------------------------------\n",
            "\u001b[92mNot_entailment (67%)\u001b[0m --> \u001b[37m[SKIPPED]\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: A plane crashed in North Carolina last year and most of the Blink-182 group was in there. The only survivors of the crash were DJ AM and musical partner Travis Barker. Less lucky, \"Lil\" Chris Baker, Barker's close friend and assistant, the Blink-182 drummer's bodyguard, Charles \"Che\" Still, the pilot and co-pilot died. Both AM and Barker suffered many injures, bad burns and they needed to stay in hospital for several weeks. Now AM asks $20 million in compensation for injuries he suffered. He lawsuits against plane maker Learjet and wants to gain $10 million for medical damages, lost earnings and profit and the same amount for mental and physical suffering.\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: Travis Barker belongs to a band.\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Total] 2 / 0 / 5:  50% 5/10 [00:07<00:07,  1.50s/it]--------------------------------------------- Result 6 ---------------------------------------------\n",
            "\u001b[92mNot_entailment (97%)\u001b[0m --> \u001b[37m[SKIPPED]\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: A farmer who was in contact with cows suffering from BSE -- the so-called mad cow disease -- has died from what is regarded as the human form of the disease.\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: Bovine spongiform encephalopathy is another name for the \"mad cow disease\".\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Total] 2 / 0 / 6:  60% 6/10 [00:07<00:05,  1.25s/it]--------------------------------------------- Result 7 ---------------------------------------------\n",
            "\u001b[92mEntailment (90%)\u001b[0m --> \u001b[92mNot_entailment (97%)\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: Evans Paul, the pro-Aristide \u001b[92mmayor\u001b[0m of Port-au-Prince, said he had been told that the money will go to American lobbyists, politicians and journalists to campaign against the return of Aristide, Haiti's first democratically elected president\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: Evans Paul is the mayor of Port-au-Prince.\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: Evans Paul, the pro-Aristide \u001b[92mmaire\u001b[0m of Port-au-Prince, said he had been told that the money will go to American lobbyists, politicians and journalists to campaign against the return of Aristide, Haiti's first democratically elected president\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: Evans Paul is the mayor of Port-au-Prince.\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Total] 3 / 0 / 7:  70% 7/10 [00:08<00:03,  1.20s/it]--------------------------------------------- Result 8 ---------------------------------------------\n",
            "\u001b[92mNot_entailment (97%)\u001b[0m --> \u001b[92mEntailment (51%)\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: Two British soldiers have been \u001b[92marrested\u001b[0m in the \u001b[92msouthern\u001b[0m Iraq \u001b[92mcity\u001b[0m of \u001b[92mBasra\u001b[0m, \u001b[92msparking\u001b[0m clashes \u001b[92moutside\u001b[0m a \u001b[92mpolice\u001b[0m station where they are being \u001b[92mheld\u001b[0m.\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: Two British \u001b[92mtanks\u001b[0m, sent to the police station where the soldiers are being held, were \u001b[92mset\u001b[0m alight in clashes.\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: Two British soldiers have been \u001b[92mdetaining\u001b[0m in the \u001b[92meastward\u001b[0m Iraq \u001b[92msuburb\u001b[0m of \u001b[92mIraqis\u001b[0m, \u001b[92minflicting\u001b[0m clashes \u001b[92mbesides\u001b[0m a \u001b[92mpolices\u001b[0m station where they are being \u001b[92morganized\u001b[0m.\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: Two British \u001b[92mreservoir\u001b[0m, sent to the police station where the soldiers are being held, were \u001b[92msetting\u001b[0m alight in clashes.\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Total] 4 / 0 / 8:  80% 8/10 [00:13<00:03,  1.69s/it]--------------------------------------------- Result 9 ---------------------------------------------\n",
            "\u001b[92mEntailment (96%)\u001b[0m --> \u001b[92mNot_entailment (67%)\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: \u001b[92msinger\u001b[0m and actress Britney Spears, 24, has filled papers in Los Angeles County Superior Court to \u001b[92mdivorce\u001b[0m her husband Kevin Federline, 28. A spokeswoman for the court, Kathy Roberts stated that the papers cited irreconcilable differences\" as the reason for the divorce and have, according to the courts, been legally separated as of Monday, November 6, the same day that Spears appeared on Late Night with David Letterman.\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: Spears is to divorce from Kevin Federline.\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: \u001b[92mchante\u001b[0m and actress Britney Spears, 24, has filled papers in Los Angeles County Superior Court to \u001b[92mmarrying\u001b[0m her husband Kevin Federline, 28. A spokeswoman for the court, Kathy Roberts stated that the papers cited irreconcilable differences\" as the reason for the divorce and have, according to the courts, been legally separated as of Monday, November 6, the same day that Spears appeared on Late Night with David Letterman.\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: Spears is to divorce from Kevin Federline.\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Total] 5 / 0 / 9:  90% 9/10 [00:16<00:01,  1.78s/it]--------------------------------------------- Result 10 ---------------------------------------------\n",
            "\u001b[92mEntailment (96%)\u001b[0m --> \u001b[92mNot_entailment (80%)\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: U.S. forces have been engaged in intense fighting after insurgents launched simultaneous attacks in several Iraqi \u001b[92mcities\u001b[0m, including Fallujah and Baqubah.\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: Fallujah and Baqubah are Iraqi cities.\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: U.S. forces have been engaged in intense fighting after insurgents launched simultaneous attacks in several Iraqi \u001b[92mville\u001b[0m, including Fallujah and Baqubah.\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: Fallujah and Baqubah are Iraqi cities.\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Total] 6 / 0 / 10: 100% 10/10 [00:17<00:00,  1.70s/it]\n",
            "\n",
            "+-------------------------------+--------+\n",
            "| Attack Results                |        |\n",
            "+-------------------------------+--------+\n",
            "| Number of successful attacks: | 6      |\n",
            "| Number of failed attacks:     | 0      |\n",
            "| Number of skipped attacks:    | 4      |\n",
            "| Original accuracy:            | 60.0%  |\n",
            "| Accuracy under attack:        | 0.0%   |\n",
            "| Attack success rate:          | 100.0% |\n",
            "| Average perturbed word %:     | 8.25%  |\n",
            "| Average num. words per input: | 60.2   |\n",
            "| Avg num queries:              | 142.17 |\n",
            "+-------------------------------+--------+\n",
            "\u001b[34;1mtextattack\u001b[0m: Attack time: 17.033098220825195s\n",
            "CPU times: user 93.1 ms, sys: 19.7 ms, total: 113 ms\n",
            "Wall time: 50.5 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrDFV60Ff3jj",
        "outputId": "34c53af5-0303-4969-9d3b-15bf9985a826"
      },
      "source": [
        "%time !textattack attack --model albert-base-v2-rte --recipe iga --num-examples 10"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reusing dataset glue (/root/.cache/huggingface/datasets/glue/rte/1.0.0/7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4)\n",
            "\u001b[34;1mtextattack\u001b[0m: Loading \u001b[94mdatasets\u001b[0m dataset \u001b[94mglue\u001b[0m, subset \u001b[94mrte\u001b[0m, split \u001b[94mvalidation\u001b[0m.\n",
            "\u001b[34;1mtextattack\u001b[0m: Loading pre-trained model from HuggingFace model repository: \u001b[94mtextattack/albert-base-v2-RTE\u001b[0m\n",
            "\u001b[34;1mtextattack\u001b[0m: Unknown if model of class <class 'transformers.models.albert.modeling_albert.AlbertForSequenceClassification'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.\n",
            "Attack(\n",
            "  (search_method): ImprovedGeneticAlgorithm(\n",
            "    (pop_size):  60\n",
            "    (max_iters):  20\n",
            "    (temp):  0.3\n",
            "    (give_up_if_no_improvement):  False\n",
            "    (post_crossover_check):  False\n",
            "    (max_crossover_retries):  20\n",
            "    (max_replace_times_per_index):  5\n",
            "  )\n",
            "  (goal_function):  UntargetedClassification\n",
            "  (transformation):  WordSwapEmbedding(\n",
            "    (max_candidates):  50\n",
            "    (embedding):  WordEmbedding\n",
            "  )\n",
            "  (constraints): \n",
            "    (0): MaxWordsPerturbed(\n",
            "        (max_percent):  0.2\n",
            "        (compare_against_original):  True\n",
            "      )\n",
            "    (1): WordEmbeddingDistance(\n",
            "        (embedding):  WordEmbedding\n",
            "        (max_mse_dist):  0.5\n",
            "        (cased):  False\n",
            "        (include_unknown_words):  True\n",
            "        (compare_against_original):  False\n",
            "      )\n",
            "    (2): StopwordModification\n",
            "  (is_black_box):  True\n",
            ") \n",
            "\n",
            "\u001b[34;1mtextattack\u001b[0m: Load time: 8.186612129211426s\n",
            "  0% 0/10 [00:00<?, ?it/s]--------------------------------------------- Result 1 ---------------------------------------------\n",
            "\u001b[92mNot_entailment (98%)\u001b[0m --> \u001b[37m[SKIPPED]\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: The Tuesday drawing of the Italian Superenalotto game has awarded the biggest prize ever won in a betting game in Italy. The single winner of the first category prize (6 numbers guessed) will receive an amount, including the jackpot from previous un-won draws, of €72.090.405,19 (US$93 million.) The prize money will be received in full without further taxation, since taxes in prizes of that type are taken at a fixed rate by the Italian State from the money paid for the bet.\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: Superenalotto awarded a prize of more than 72 million euros.\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Total] 0 / 0 / 1:  10% 1/10 [00:00<00:00, 20.36it/s]--------------------------------------------- Result 2 ---------------------------------------------\n",
            "\u001b[92mEntailment (78%)\u001b[0m --> \u001b[92mNot_entailment (83%)\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: Rotorua has banned criminals with five or more dishonesty convictions from entering the Central Business District (CBD). The criminals will be issued with trespass notices banning them from the main streets of Rotorua. Eleven out of twelve councillors, including the Rotorua mayor, supported the by-law along with support from the police. Kevin Winters, Mayor of Rotorua, said \"The ban also had the support of local businesses, who wanted an end to the thefts, assaults, shoplifting and other street crime on Rotorua streets. Crime was an issue in the area. Five strikes and you're out.\"\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: The Central Business \u001b[92mDistrict\u001b[0m (CBD) is part of Rotorua.\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: Rotorua has banned criminals with five or more dishonesty convictions from entering the Central Business District (CBD). The criminals will be issued with trespass notices banning them from the main streets of Rotorua. Eleven out of twelve councillors, including the Rotorua mayor, supported the by-law along with support from the police. Kevin Winters, Mayor of Rotorua, said \"The ban also had the support of local businesses, who wanted an end to the thefts, assaults, shoplifting and other street crime on Rotorua streets. Crime was an issue in the area. Five strikes and you're out.\"\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: The Central Business \u001b[92mBorough\u001b[0m (CBD) is part of Rotorua.\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Total] 1 / 0 / 2:  20% 2/10 [01:05<04:21, 32.75s/it]--------------------------------------------- Result 3 ---------------------------------------------\n",
            "\u001b[92mNot_entailment (95%)\u001b[0m --> \u001b[92mEntailment (57%)\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: Mrs. Bush's approval \u001b[92mratings\u001b[0m have \u001b[92mremained\u001b[0m very \u001b[92mhigh\u001b[0m, above 80%, even as her husband's have recently dropped below 50%.\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: 80% \u001b[92mapprove\u001b[0m of \u001b[92mMr\u001b[0m. Bush.\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: Mrs. Bush's approval \u001b[92mpunctuation\u001b[0m have \u001b[92mremains\u001b[0m very \u001b[92msuperior\u001b[0m, above 80%, even as her husband's have recently dropped below 50%.\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: 80% \u001b[92mapproval\u001b[0m of \u001b[92mMonsieur\u001b[0m. Bush.\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Total] 2 / 0 / 3:  30% 3/10 [01:30<03:31, 30.25s/it]--------------------------------------------- Result 4 ---------------------------------------------\n",
            "\u001b[92mNot_entailment (89%)\u001b[0m --> \u001b[37m[SKIPPED]\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: Nokia, Texas Instruments and other leading makers of mobile phones have formally complained to Brussels that Qualcomm, the US mobile chipmaker, has unfairly used its patents on 3G technologies.\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: Texas Instruments produces mobile phones.\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Total] 2 / 0 / 4:  40% 4/10 [01:30<02:16, 22.69s/it]--------------------------------------------- Result 5 ---------------------------------------------\n",
            "\u001b[92mNot_entailment (67%)\u001b[0m --> \u001b[37m[SKIPPED]\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: A plane crashed in North Carolina last year and most of the Blink-182 group was in there. The only survivors of the crash were DJ AM and musical partner Travis Barker. Less lucky, \"Lil\" Chris Baker, Barker's close friend and assistant, the Blink-182 drummer's bodyguard, Charles \"Che\" Still, the pilot and co-pilot died. Both AM and Barker suffered many injures, bad burns and they needed to stay in hospital for several weeks. Now AM asks $20 million in compensation for injuries he suffered. He lawsuits against plane maker Learjet and wants to gain $10 million for medical damages, lost earnings and profit and the same amount for mental and physical suffering.\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: Travis Barker belongs to a band.\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Total] 2 / 0 / 5:  50% 5/10 [01:30<01:30, 18.16s/it]--------------------------------------------- Result 6 ---------------------------------------------\n",
            "\u001b[92mNot_entailment (97%)\u001b[0m --> \u001b[37m[SKIPPED]\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: A farmer who was in contact with cows suffering from BSE -- the so-called mad cow disease -- has died from what is regarded as the human form of the disease.\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: Bovine spongiform encephalopathy is another name for the \"mad cow disease\".\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Total] 2 / 0 / 6:  60% 6/10 [01:30<01:00, 15.13s/it]--------------------------------------------- Result 7 ---------------------------------------------\n",
            "\u001b[92mEntailment (90%)\u001b[0m --> \u001b[92mNot_entailment (97%)\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: Evans Paul, the pro-Aristide mayor of Port-au-Prince, said he had been told that the money will go to American lobbyists, politicians and journalists to campaign against the return of Aristide, Haiti's first democratically elected president\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: Evans Paul is the \u001b[92mmayor\u001b[0m of Port-au-Prince.\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: Evans Paul, the pro-Aristide mayor of Port-au-Prince, said he had been told that the money will go to American lobbyists, politicians and journalists to campaign against the return of Aristide, Haiti's first democratically elected president\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: Evans Paul is the \u001b[92mmaire\u001b[0m of Port-au-Prince.\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Total] 3 / 0 / 7:  70% 7/10 [01:51<00:47, 15.98s/it]--------------------------------------------- Result 8 ---------------------------------------------\n",
            "\u001b[92mNot_entailment (97%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: Two British soldiers have been arrested in the southern Iraq city of Basra, sparking clashes outside a police station where they are being held.\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: Two British tanks, sent to the police station where the soldiers are being held, were set alight in clashes.\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Total] 3 / 1 / 8:  80% 8/10 [05:50<01:27, 43.78s/it]--------------------------------------------- Result 9 ---------------------------------------------\n",
            "\u001b[92mEntailment (96%)\u001b[0m --> \u001b[92mNot_entailment (97%)\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: singer and actress Britney Spears, 24, has filled papers in Los Angeles County Superior Court to divorce her husband Kevin Federline, 28. A spokeswoman for the court, Kathy Roberts stated that the papers cited irreconcilable differences\" as the reason for the divorce and have, according to the courts, been legally separated as of Monday, November 6, the same day that Spears appeared on Late Night with David Letterman.\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: \u001b[92mSpears\u001b[0m is to divorce from Kevin Federline.\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: singer and actress Britney Spears, 24, has filled papers in Los Angeles County Superior Court to divorce her husband Kevin Federline, 28. A spokeswoman for the court, Kathy Roberts stated that the papers cited irreconcilable differences\" as the reason for the divorce and have, according to the courts, been legally separated as of Monday, November 6, the same day that Spears appeared on Late Night with David Letterman.\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: \u001b[92mSpurs\u001b[0m is to divorce from Kevin Federline.\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Total] 4 / 1 / 9:  90% 9/10 [06:07<00:40, 40.83s/it]--------------------------------------------- Result 10 ---------------------------------------------\n",
            "\u001b[92mEntailment (96%)\u001b[0m --> \u001b[92mNot_entailment (96%)\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: U.S. forces have been engaged in intense fighting after insurgents launched simultaneous attacks in several Iraqi \u001b[92mcities\u001b[0m, including Fallujah and Baqubah.\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: Fallujah and Baqubah are Iraqi cities.\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: U.S. forces have been engaged in intense fighting after insurgents launched simultaneous attacks in several Iraqi \u001b[92mtownships\u001b[0m, including Fallujah and Baqubah.\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: Fallujah and Baqubah are Iraqi cities.\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Total] 5 / 1 / 10: 100% 10/10 [06:12<00:00, 37.20s/it]\n",
            "\n",
            "+-------------------------------+---------+\n",
            "| Attack Results                |         |\n",
            "+-------------------------------+---------+\n",
            "| Number of successful attacks: | 5       |\n",
            "| Number of failed attacks:     | 1       |\n",
            "| Number of skipped attacks:    | 4       |\n",
            "| Original accuracy:            | 60.0%   |\n",
            "| Accuracy under attack:        | 10.0%   |\n",
            "| Attack success rate:          | 83.33%  |\n",
            "| Average perturbed word %:     | 5.82%   |\n",
            "| Average num. words per input: | 60.2    |\n",
            "| Avg num queries:              | 3082.17 |\n",
            "+-------------------------------+---------+\n",
            "\u001b[34;1mtextattack\u001b[0m: Attack time: 372.01856231689453s\n",
            "CPU times: user 394 ms, sys: 89.2 ms, total: 483 ms\n",
            "Wall time: 6min 31s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98v4kEOkkcMS",
        "outputId": "f4fffdc5-4e09-4e6c-c010-3281b2a86767"
      },
      "source": [
        "%time !textattack attack --model albert-base-v2-rte --recipe faster-alzantot --num-examples 10"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reusing dataset glue (/root/.cache/huggingface/datasets/glue/rte/1.0.0/7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4)\n",
            "\u001b[34;1mtextattack\u001b[0m: Loading \u001b[94mdatasets\u001b[0m dataset \u001b[94mglue\u001b[0m, subset \u001b[94mrte\u001b[0m, split \u001b[94mvalidation\u001b[0m.\n",
            "\u001b[34;1mtextattack\u001b[0m: Loading pre-trained model from HuggingFace model repository: \u001b[94mtextattack/albert-base-v2-RTE\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:61: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.01 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "\u001b[34;1mtextattack\u001b[0m: Unknown if model of class <class 'transformers.models.albert.modeling_albert.AlbertForSequenceClassification'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.\n",
            "Attack(\n",
            "  (search_method): AlzantotGeneticAlgorithm(\n",
            "    (pop_size):  60\n",
            "    (max_iters):  20\n",
            "    (temp):  0.3\n",
            "    (give_up_if_no_improvement):  False\n",
            "    (post_crossover_check):  False\n",
            "    (max_crossover_retries):  20\n",
            "  )\n",
            "  (goal_function):  UntargetedClassification\n",
            "  (transformation):  WordSwapEmbedding(\n",
            "    (max_candidates):  8\n",
            "    (embedding):  WordEmbedding\n",
            "  )\n",
            "  (constraints): \n",
            "    (0): MaxWordsPerturbed(\n",
            "        (max_percent):  0.2\n",
            "        (compare_against_original):  True\n",
            "      )\n",
            "    (1): WordEmbeddingDistance(\n",
            "        (embedding):  WordEmbedding\n",
            "        (max_mse_dist):  0.5\n",
            "        (cased):  False\n",
            "        (include_unknown_words):  True\n",
            "        (compare_against_original):  True\n",
            "      )\n",
            "    (2): LearningToWriteLanguageModel(\n",
            "        (max_log_prob_diff):  5.0\n",
            "        (compare_against_original):  True\n",
            "      )\n",
            "    (3): RepeatModification\n",
            "    (4): StopwordModification\n",
            "  (is_black_box):  True\n",
            ") \n",
            "\n",
            "\u001b[34;1mtextattack\u001b[0m: Load time: 15.367020845413208s\n",
            "  0% 0/10 [00:00<?, ?it/s]--------------------------------------------- Result 1 ---------------------------------------------\n",
            "\u001b[92mNot_entailment (98%)\u001b[0m --> \u001b[37m[SKIPPED]\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: The Tuesday drawing of the Italian Superenalotto game has awarded the biggest prize ever won in a betting game in Italy. The single winner of the first category prize (6 numbers guessed) will receive an amount, including the jackpot from previous un-won draws, of €72.090.405,19 (US$93 million.) The prize money will be received in full without further taxation, since taxes in prizes of that type are taken at a fixed rate by the Italian State from the money paid for the bet.\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: Superenalotto awarded a prize of more than 72 million euros.\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Total] 0 / 0 / 1:  10% 1/10 [00:00<00:00, 44.38it/s]--------------------------------------------- Result 2 ---------------------------------------------\n",
            "\u001b[92mEntailment (78%)\u001b[0m --> \u001b[92mNot_entailment (52%)\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: Rotorua has banned criminals with five or more dishonesty convictions from entering the Central Business \u001b[92mDistrict\u001b[0m (CBD). The criminals will be issued with trespass notices banning them from the main streets of Rotorua. Eleven out of twelve councillors, including the Rotorua mayor, supported the by-law along with support from the police. Kevin Winters, Mayor of Rotorua, said \"The ban also had the support of local businesses, who wanted an end to the thefts, assaults, shoplifting and other street crime on Rotorua streets. Crime was an issue in the area. Five strikes and you're out.\"\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: The Central Business District (CBD) is part of Rotorua.\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: Rotorua has banned criminals with five or more dishonesty convictions from entering the Central Business \u001b[92mRegion\u001b[0m (CBD). The criminals will be issued with trespass notices banning them from the main streets of Rotorua. Eleven out of twelve councillors, including the Rotorua mayor, supported the by-law along with support from the police. Kevin Winters, Mayor of Rotorua, said \"The ban also had the support of local businesses, who wanted an end to the thefts, assaults, shoplifting and other street crime on Rotorua streets. Crime was an issue in the area. Five strikes and you're out.\"\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: The Central Business District (CBD) is part of Rotorua.\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Total] 1 / 0 / 2:  20% 2/10 [00:24<01:38, 12.32s/it]--------------------------------------------- Result 3 ---------------------------------------------\n",
            "\u001b[92mNot_entailment (95%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: Mrs. Bush's approval ratings have remained very high, above 80%, even as her husband's have recently dropped below 50%.\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: 80% approve of Mr. Bush.\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Total] 1 / 1 / 3:  30% 3/10 [06:35<15:22, 131.78s/it]--------------------------------------------- Result 4 ---------------------------------------------\n",
            "\u001b[92mNot_entailment (89%)\u001b[0m --> \u001b[37m[SKIPPED]\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: Nokia, Texas Instruments and other leading makers of mobile phones have formally complained to Brussels that Qualcomm, the US mobile chipmaker, has unfairly used its patents on 3G technologies.\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: Texas Instruments produces mobile phones.\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Total] 1 / 1 / 4:  40% 4/10 [06:35<09:53, 98.84s/it] --------------------------------------------- Result 5 ---------------------------------------------\n",
            "\u001b[92mNot_entailment (67%)\u001b[0m --> \u001b[37m[SKIPPED]\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: A plane crashed in North Carolina last year and most of the Blink-182 group was in there. The only survivors of the crash were DJ AM and musical partner Travis Barker. Less lucky, \"Lil\" Chris Baker, Barker's close friend and assistant, the Blink-182 drummer's bodyguard, Charles \"Che\" Still, the pilot and co-pilot died. Both AM and Barker suffered many injures, bad burns and they needed to stay in hospital for several weeks. Now AM asks $20 million in compensation for injuries he suffered. He lawsuits against plane maker Learjet and wants to gain $10 million for medical damages, lost earnings and profit and the same amount for mental and physical suffering.\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: Travis Barker belongs to a band.\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Total] 1 / 1 / 5:  50% 5/10 [06:35<06:35, 79.07s/it]--------------------------------------------- Result 6 ---------------------------------------------\n",
            "\u001b[92mNot_entailment (97%)\u001b[0m --> \u001b[37m[SKIPPED]\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: A farmer who was in contact with cows suffering from BSE -- the so-called mad cow disease -- has died from what is regarded as the human form of the disease.\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: Bovine spongiform encephalopathy is another name for the \"mad cow disease\".\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Total] 1 / 1 / 6:  60% 6/10 [06:35<04:23, 65.90s/it]--------------------------------------------- Result 7 ---------------------------------------------\n",
            "\u001b[92mEntailment (90%)\u001b[0m --> \u001b[92mNot_entailment (93%)\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: Evans \u001b[92mPaul\u001b[0m, the pro-Aristide mayor of Port-au-Prince, said he had been told that the money will go to American lobbyists, politicians and journalists to campaign against the return of Aristide, Haiti's first democratically elected president\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: Evans Paul is the mayor of Port-au-Prince.\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: Evans \u001b[92mPaulo\u001b[0m, the pro-Aristide mayor of Port-au-Prince, said he had been told that the money will go to American lobbyists, politicians and journalists to campaign against the return of Aristide, Haiti's first democratically elected president\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: Evans Paul is the mayor of Port-au-Prince.\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Total] 2 / 1 / 7:  70% 7/10 [06:54<02:57, 59.24s/it]--------------------------------------------- Result 8 ---------------------------------------------\n",
            "\u001b[92mNot_entailment (97%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: Two British soldiers have been arrested in the southern Iraq city of Basra, sparking clashes outside a police station where they are being held.\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: Two British tanks, sent to the police station where the soldiers are being held, were set alight in clashes.\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Total] 2 / 2 / 8:  80% 8/10 [14:32<03:38, 109.04s/it]--------------------------------------------- Result 9 ---------------------------------------------\n",
            "\u001b[92mEntailment (96%)\u001b[0m --> \u001b[92mNot_entailment (54%)\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: singer and actress Britney Spears, 24, has filled \u001b[92mpapers\u001b[0m in Los Angeles County Superior Court to \u001b[92mdivorce\u001b[0m her husband Kevin Federline, 28. A spokeswoman for the \u001b[92mcourt\u001b[0m, Kathy Roberts stated that the papers \u001b[92mcited\u001b[0m irreconcilable differences\" as the reason for the divorce and have, according to the courts, been legally separated as of Monday, November 6, the same day that \u001b[92mSpears\u001b[0m appeared on Late Night with David Letterman.\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: Spears is to divorce from Kevin Federline.\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: singer and actress Britney Spears, 24, has filled \u001b[92mdocumentation\u001b[0m in Los Angeles County Superior Court to \u001b[92mdivorcing\u001b[0m her husband Kevin Federline, 28. A spokeswoman for the \u001b[92mtribunal\u001b[0m, Kathy Roberts stated that the papers \u001b[92mmention\u001b[0m irreconcilable differences\" as the reason for the divorce and have, according to the courts, been legally separated as of Monday, November 6, the same day that \u001b[92mSpurs\u001b[0m appeared on Late Night with David Letterman.\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: Spears is to divorce from Kevin Federline.\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Total] 3 / 2 / 9:  90% 9/10 [15:31<01:43, 103.51s/it]--------------------------------------------- Result 10 ---------------------------------------------\n",
            "\u001b[92mEntailment (96%)\u001b[0m --> \u001b[92mNot_entailment (76%)\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: U.S. forces have been engaged in intense fighting after insurgents launched \u001b[92msimultaneous\u001b[0m attacks in several Iraqi cities, including Fallujah and Baqubah.\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: Fallujah and Baqubah are \u001b[92mIraqi\u001b[0m cities.\n",
            "\n",
            "\u001b[1m\u001b[4mSentence1\u001b[0m\u001b[0m: U.S. forces have been engaged in intense fighting after insurgents launched \u001b[92mconcurrent\u001b[0m attacks in several Iraqi cities, including Fallujah and Baqubah.\n",
            "\u001b[1m\u001b[4mSentence2\u001b[0m\u001b[0m: Fallujah and Baqubah are \u001b[92mBaghdad\u001b[0m cities.\n",
            "\n",
            "\n",
            "[Succeeded / Failed / Total] 4 / 2 / 10: 100% 10/10 [15:45<00:00, 94.55s/it]\n",
            "\n",
            "+-------------------------------+---------+\n",
            "| Attack Results                |         |\n",
            "+-------------------------------+---------+\n",
            "| Number of successful attacks: | 4       |\n",
            "| Number of failed attacks:     | 2       |\n",
            "| Number of skipped attacks:    | 4       |\n",
            "| Original accuracy:            | 60.0%   |\n",
            "| Accuracy under attack:        | 20.0%   |\n",
            "| Attack success rate:          | 66.67%  |\n",
            "| Average perturbed word %:     | 4.29%   |\n",
            "| Average num. words per input: | 60.2    |\n",
            "| Avg num queries:              | 2021.67 |\n",
            "+-------------------------------+---------+\n",
            "\u001b[34;1mtextattack\u001b[0m: Attack time: 945.5397796630859s\n",
            "CPU times: user 1.7 s, sys: 314 ms, total: 2.01 s\n",
            "Wall time: 16min 11s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUYRzSV0f7HN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}